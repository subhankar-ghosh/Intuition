---
title: "Intuition"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Tree Based Models

#### What is a tree?

Tree is a very common and powerful data structure in Computer Science. If we use/construct the tree properly the 
operation time reduces to $O(log(N))$ where $N$ is the number of data points. Thus it becomes of interest in
Machine Learning as well since we almost always want the results to come immediately.

#### Umm! I did not quite understand how that works properly! How is it used in Machine Learning again?

Well as seen in the picture the height of a tree is of the order $log(N)$ and to answer a query we only need to 
traverse one branch and NOT all the branches, so literally if you are unlucky *(The Worst Case)* you have to
traverse the entire height .ie. of the order $log(N)$.

At first let us say we divide S into two sub spaces $S_1$ if $X_1 \le t_1 and S_2 otherwise$. 

Then recursively we partition $S_1$ into $S_11$ and $S_12$ if $X_2 \le t_2$ and $X_2 \gt t_2$ respectively. And lets say we divide $S_2$ into $S_21$ and $S_22$ based on $X_1 \le t_3$ or not. This process continues untill a *convergence criteria* is reached. So if I have to write a pseudo code then it would look like this: [Read More](tree.html)

## Monte Carlo Approximation

If you have a random variable X with a known distribution (for example Uniform Distribution or Normal Distribution), but now you are solving a problem which requires knowing about the distribution of a function of the random variable X $f(X)$. What are the paths you can travel to solve it?  [Read More](montecarlo.html)

##### Hope you learnt something and enjoyed it! Stay tuned for more articles!

